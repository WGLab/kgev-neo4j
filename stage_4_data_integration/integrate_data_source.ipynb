{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables below should be updated accordingly.  \n",
    "`INPUT_FILE_PATH` is where the processed SemRep triples is stored (output of Stage 2).  \n",
    "`OUTPUT_FILE_PATH` is where the integrated triples/the output from Stage 4 will be stored (as a .csv file).  \n",
    "`NODE_MAPPING_FILE_PATH` is where node information for the processed triples is stored (output of Stage 2).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH = '../data/semrep_relationships_processed.csv'\n",
    "OUTPUT_FILE_PATH = '../data/semrep_relationships_integrated.csv'\n",
    "NODE_MAPPING_FILE_PATH = '../data/node_id_mapping.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'integration_data_processed' # processed data from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns in the edges file\n",
    "id_col = 'id' # the preferred name of the entity\n",
    "id_col_1 = id_col + \"1\"\n",
    "id_col_2 = id_col + \"2\"\n",
    "\n",
    "identifier_col = 'identifier' # the CUI of the entity\n",
    "identifier_col_1 = identifier_col + \"1\"\n",
    "identifier_col_2 = identifier_col + \"2\"\n",
    "\n",
    "type_col = 'type' # the semantic group of the entity\n",
    "type_col_1 = type_col + \"1\"\n",
    "type_col_2 = type_col + \"2\"\n",
    "\n",
    "info_col = 'info' # synonyms/original texts for the entity\n",
    "info_col_1 = info_col + \"1\"\n",
    "info_col_2 = info_col + \"2\"\n",
    "\n",
    "source_col = 'evidence_source' # what source the triple is from\n",
    "rel_col = ':TYPE' # relationship\n",
    "weight_col = 'weight' # name of column with triple edge weight\n",
    "\n",
    "# what to name the columns after aggregation\n",
    "identifier_col_agg = identifier_col + \"s\"\n",
    "type_col_agg = type_col + \"s\"\n",
    "info_col_agg = info_col + \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header is the output column format/order\n",
    "literature_df = pd.read_csv(INPUT_FILE_PATH)\n",
    "header = list(literature_df.columns)\n",
    "literature_df.to_csv(OUTPUT_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize entity names using node mapping file\n",
    "def standardize_ents(df, nodes_df):\n",
    "    df = df.merge(nodes_df[[identifier_col, id_col, info_col_agg, type_col_agg, identifier_col_agg]], left_on=identifier_col_1, right_on=identifier_col, how='left').drop([identifier_col, identifier_col_1], axis=1).rename(columns={identifier_col_agg: identifier_col_1, type_col_agg: type_col_1, info_col_agg: info_col_1, id_col: id_col_1})\n",
    "    df = df.merge(nodes_df[[identifier_col, id_col, info_col_agg, type_col_agg, identifier_col_agg]], left_on=identifier_col_2, right_on=identifier_col, how='left').drop([identifier_col, identifier_col_2], axis=1).rename(columns={identifier_col_agg: identifier_col_2, type_col_agg: type_col_2, info_col_agg: info_col_2, id_col: id_col_2})\n",
    "    return df\n",
    "\n",
    "def integrate_edgefile(header, nodes_filename, source_filename, output_filename, ent1_type, ent1_col, ent2_type, ent2_col, source, weight_col_source, processing_function, weight_col, source_col, identifier_col, id_col, type_col, relationship, ent1_gene=False, ent2_gene=False):\n",
    "    # header: output column format.order\n",
    "    # nodes_filename: file that has desired knowledge graph nodes\n",
    "    # source_filename: input filename\n",
    "    # output_filename: output filename\n",
    "\n",
    "    # ent1_type: type the first entity should be\n",
    "    # ent1_col: name of the column in the source that has the first entity\n",
    "    # ent2_type: type the second entity should be\n",
    "    # ent2_col: name of the column in the source that has the second entity\n",
    "\n",
    "    # source: source name of relationships\n",
    "    # weight_col_source: weight column in source file\n",
    "\n",
    "    # weight_col: name of source column in output\n",
    "    # source_col: name of source column in output\n",
    "\n",
    "    # identifier_col: name of column that refers to the node ID (used to filter the source)\n",
    "    # id_col: id used to standardize entities\n",
    "    # type_col: name of column that refers to the node type\n",
    "\n",
    "    # get all IDs for ent1 and ent2 types from nodes_df\n",
    "    nodes_df = pd.read_csv(nodes_filename)\n",
    "    if ent1_type and ent2_type:\n",
    "        ent1_all_ids = set(nodes_df.loc[nodes_df[type_col] == ent1_type, identifier_col])\n",
    "        ent2_all_ids = set(nodes_df.loc[nodes_df[type_col] == ent2_type, identifier_col])\n",
    "#         ent1_all_ids = set(nodes_df[nodes_df[type_col] == ent1_type][identifier_col])\n",
    "#         ent2_all_ids = set(nodes_df[nodes_df[type_col] == ent2_type][identifier_col])\n",
    "    else:\n",
    "        ent1_all_ids = set(nodes_df[identifier_col])\n",
    "        ent2_all_ids = set(nodes_df[identifier_col])\n",
    "    \n",
    "    # filter for required nodes\n",
    "    source_df = pd.read_csv(source_filename)    \n",
    "    # filter\n",
    "    source_df = source_df[(source_df[ent1_col].isin(ent1_all_ids))&(source_df[ent2_col].isin(ent2_all_ids))]\n",
    "        \n",
    "    # set weight to zero if there is no weight column in the data\n",
    "    if not weight_col_source:\n",
    "        weight_col_source = 'weight_col_source'\n",
    "        source_df[weight_col_source] = 0\n",
    "    \n",
    "    edges_df = source_df.loc[:,[ent1_col, ent2_col, weight_col_source]]\n",
    "    edges_df.columns = [identifier_col_1, identifier_col_2, weight_col]\n",
    "    edges_df[source_col] = source\n",
    "    edges_df[\":TYPE\"] = relationship\n",
    "    \n",
    "    # standardize entities\n",
    "    edges_df = processing_function(edges_df, nodes_df)\n",
    "    \n",
    "    # make sure columns in edges file output is in correct order\n",
    "    for col in header:\n",
    "        if not col in edges_df.columns:\n",
    "            edges_df.loc[:,col] = np.nan\n",
    "\n",
    "    edges_df = edges_df[header]\n",
    "    edges_df.drop_duplicates(inplace=True)\n",
    "    edges_df = edges_df[edges_df[id_col_1] != edges_df[id_col_2]] # remove self loops\n",
    "    print(f'{len(edges_df)} edges added from source {source_filename}')\n",
    "    print()\n",
    "    edges_df.to_csv(output_filename, mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5679 edges added from source integration_data_processed/disease_gene_relationships.csv\n",
      "\n",
      "2891 edges added from source integration_data_processed/drug_gene_relationships.csv\n",
      "\n",
      "21700 edges added from source integration_data_processed/gene_gene_relationships.csv\n",
      "\n",
      "6837 edges added from source integration_data_processed/gene_GO_relationships.csv\n",
      "\n",
      "7879 edges added from source integration_data_processed/gene_phenotype_relationships.csv\n",
      "\n",
      "1748 edges added from source integration_data_processed/disease_phenotype_relationships.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# disease-gene relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'disease_gene_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_disease', ent2_type=None, ent2_col='CUI_gene', source='DisGeNET', weight_col_source='score', processing_function=standardize_ents, weight_col=weight_col, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='disease-gene')\n",
    "\n",
    "# drug-gene relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'drug_gene_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_drug', ent2_type=None, ent2_col='CUI_gene', source='DGIdb', weight_col_source='interaction_group_score', processing_function=standardize_ents, weight_col=weight_col, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='drug-gene')\n",
    "\n",
    "# gene-gene relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'gene_gene_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_gene_1', ent2_type=None, ent2_col='CUI_gene_2', source='STRING', weight_col_source='combined_score', processing_function=standardize_ents, weight_col=weight_col, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='gene-gene')\n",
    "\n",
    "# gene-GO relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'gene_GO_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_gene', ent2_type=None, ent2_col='CUI_GO', source='Uniprot', weight_col_source=None, weight_col=weight_col, processing_function=standardize_ents, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='gene-GO')\n",
    "\n",
    "# gene-phenotype relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'gene_phenotype_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_gene', ent2_type=None, ent2_col='CUI_HPO', source='HPO', weight_col_source=None, weight_col=weight_col, processing_function=standardize_ents, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='gene-phenotype')\n",
    "\n",
    "# disease-phenotype relationships\n",
    "integrate_edgefile(header=header, nodes_filename=NODE_MAPPING_FILE_PATH, source_filename=os.path.join(DATA_DIR, 'disease_phenotype_relationships.csv'), output_filename=OUTPUT_FILE_PATH, ent1_type=None, ent1_col='CUI_disease', ent2_type=None, ent2_col='CUI_HPO', source='HPO', weight_col_source=None, weight_col=weight_col, processing_function=standardize_ents, source_col=source_col, identifier_col=identifier_col, id_col=id_col, type_col=type_col, relationship='disease-phenotype')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
